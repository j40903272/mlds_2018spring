{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450 training files\n",
      "1450 training data\n",
      "1450 training labels\n"
     ]
    }
   ],
   "source": [
    "train_id_list = open('hw2_1_data/training_data/id.txt').read().split()\n",
    "train_data = {i:np.load('hw2_1_data/training_data/feat/'+ i + '.npy') for i in train_id_list}\n",
    "train_label = json.loads(open('hw2_1_data/training_label.json', 'r').read())\n",
    "# label = list -> dict['caption'] -> list (variable length???)\n",
    "\n",
    "print (len(train_id_list), 'training files')\n",
    "print (len(train_data), 'training data')\n",
    "print (len(train_label), 'training labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 testing files\n",
      "100 testing data\n",
      "100 testing labels\n"
     ]
    }
   ],
   "source": [
    "test_id_list = open('hw2_1_data/testing_data/id.txt').read().split()\n",
    "test_data = {i:np.load('hw2_1_data/testing_data/feat/'+ i + '.npy') for i in test_id_list}\n",
    "test_label = json.loads(open('hw2_1_data/testing_label.json', 'r').read())\n",
    "# label = list -> dict['caption'] -> list (variable length???)\n",
    "\n",
    "print (len(test_id_list), 'testing files')\n",
    "print (len(test_data), 'testing data')\n",
    "print (len(test_label), 'testing labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v = w2v_model.wv\n",
    "#del w2v_model\n",
    "\n",
    "w_rank = {}\n",
    "for i,word in enumerate(w2v_model.index2word):\n",
    "    w_rank[word] = i\n",
    "\n",
    "WORDS = w_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from autocorrect import spell\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('all_caption', 'w')as f:\n",
    "    for i in train_label:\n",
    "        for j in i['caption']:\n",
    "            f.write(j+'\\n')\n",
    "    for i in test_label:\n",
    "        for j in i['caption']:\n",
    "            f.write(j+'\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "WORDS = Counter(words(open('all_caption').read()))\n",
    "\n",
    "def P(word):\n",
    "    \"Probability of `word`.\"\n",
    "    # use inverse of rank as proxy\n",
    "    # returns 0 if the word isn't in the dictionary\n",
    "    return - WORDS.get(word, 0)\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# glove\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6222 words\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "# fit_on_texts(texts)\n",
    "# texts: can be a list of strings, generator of strings, or a list of list of strings.\n",
    "\n",
    "for i in train_label:\n",
    "    t.fit_on_texts(i['caption'])\n",
    "    \n",
    "for i in test_label:\n",
    "    t.fit_on_texts(i['caption'])\n",
    "    \n",
    "print (len(t.word_counts), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1450\n",
      "test 100\n"
     ]
    }
   ],
   "source": [
    "# misspelling correction\n",
    "correct_words = {}\n",
    "\n",
    "for i in train_label:\n",
    "    new = []\n",
    "    for j in i['caption']:\n",
    "        tmp = text_to_word_sequence(j)\n",
    "        correct_list = []\n",
    "        for k in range(len(tmp)):\n",
    "            ignore_this_word = False\n",
    "            for l in tmp[k]:\n",
    "                if l not in string.ascii_letters and l not in [\" \", \"'\"]:\n",
    "                    #print ('######', l, tmp[k], tmp)\n",
    "                    ignore_this_word = True\n",
    "                    break\n",
    "            if ignore_this_word:\n",
    "                continue\n",
    "            corrected = spell(tmp[k])\n",
    "            if corrected != tmp[k] and corrected in t.word_counts and t.word_counts[corrected] > t.word_counts[tmp[k]]*5 and t.word_counts[tmp[k]] < 10 and tmp[k][-2:] != \"'s\":\n",
    "                #print (tmp[k], t.word_counts[tmp[k]], corrected, t.word_counts[corrected], tmp)\n",
    "                correct_words[tmp[k]] = corrected\n",
    "                correct_list.append(corrected)\n",
    "            else:\n",
    "                correct_list.append(tmp[k])\n",
    "                \n",
    "        new.append(\" \".join(correct_list))\n",
    "    i['caption'] = new\n",
    "    \n",
    "\n",
    "print ('train', len(train_label))\n",
    "print ('test', len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6061 words\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "# fit_on_texts(texts)\n",
    "# texts: can be a list of strings, generator of strings, or a list of list of strings.\n",
    "\n",
    "for i in train_label:\n",
    "    t.fit_on_texts(i['caption'])\n",
    "    \n",
    "for i in test_label:\n",
    "    t.fit_on_texts(i['caption'])\n",
    "    \n",
    "print (len(t.word_counts), 'words')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# choose label\n",
    "org_test_label = test_label.copy()\n",
    "org_train_label = train_label.copy()\n",
    "\n",
    "for i in train_label:\n",
    "    new = []\n",
    "    for j in i['caption']:\n",
    "        tmp = text_to_word_sequence(j)\n",
    "        if len(tmp) < 10:\n",
    "            new.append(j)\n",
    "    i['caption'] = new\n",
    "    \n",
    "for i in test_label:\n",
    "    new = []\n",
    "    for j in i['caption']:\n",
    "        tmp = text_to_word_sequence(j)\n",
    "        if len(tmp) < 10:\n",
    "            new.append(j)\n",
    "    i['caption'] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "\n",
    "in_length = 80\n",
    "out_length = 20\n",
    "batch_size = 32\n",
    "emb_size = 100\n",
    "epochs = 20\n",
    "latent_dim = 256\n",
    "input_dim = 4096\n",
    "drop_rate = 0.5\n",
    "vocab_size = len(t.word_counts) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2idx = dict((i, t.word_index[i]) for i in t.word_index)\n",
    "idx2vocab = dict((t.word_index[i], i) for i in t.word_index)\n",
    "idx2vocab[0] = \"<pad>\"\n",
    "idx2vocab[vocab_size] = \"<S>\"\n",
    "#idx2vocab[6224] = \"<E>\"\n",
    "#idx2vocab[6225] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length: 42\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sequence length analysis\n",
    "\n",
    "seq_length = []\n",
    "max_seq_length = 0\n",
    "\n",
    "for i in train_label:\n",
    "    seqs = t.texts_to_sequences(i['caption']) # input a list of strings\n",
    "    for j in seqs:\n",
    "        seq_length.append(len(j))\n",
    "        max_seq_length = max(len(j), max_seq_length)\n",
    "for i in test_label:\n",
    "    seqs = t.texts_to_sequences(i['caption']) # input a list of strings\n",
    "    for j in seqs:\n",
    "        seq_length.append(len(j))\n",
    "        max_seq_length = max(len(j), max_seq_length)\n",
    "\n",
    "print ('max_seq_length:', max_seq_length)\n",
    "plt.hist(seq_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_label:\n",
    "    seqs = t.texts_to_sequences(i['caption']) # input a list of strings\n",
    "    seqs = [[vocab_size]+j for j in seqs] # put start symbol <S> at begining\n",
    "    pad_seqs = pad_sequences(seqs, maxlen=out_length, dtype='int32', padding='post', truncating='post', value=0.0)\n",
    "    i['seq'] = pad_seqs\n",
    "for i in test_label:\n",
    "    seqs = t.texts_to_sequences(i['caption']) # input a list of strings\n",
    "    seqs = [[vocab_size]+j for j in seqs] # put start symbol <S> at begining\n",
    "    pad_seqs = pad_sequences(seqs, maxlen=out_length, dtype='int32', padding='post', truncating='post', value=0.0)\n",
    "    i['seq'] = pad_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data (24232,) train target (24232, 2)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i, ii in enumerate(train_label):\n",
    "    for j, jj in enumerate(ii['seq']):\n",
    "        X.append(ii['id'])\n",
    "        Y.append([i, j])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print ('train data', X.shape, 'train target', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data (1674,) test target (1674, 2)\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for i, ii in enumerate(test_label):\n",
    "    for j, jj in enumerate(ii['seq']):\n",
    "        X_test.append(ii['id'])\n",
    "        Y_test.append([i, j])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "print ('test data', X_test.shape, 'test target', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, RepeatVector, Dropout, Embedding, Concatenate, Permute, Reshape, merge\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnt = 0\n",
    "embedding_matrix = np.zeros((vocab_size+1, emb_size))\n",
    "for i in range(vocab_size+1):\n",
    "    if idx2vocab[i] in embeddings_index:\n",
    "        embedding_matrix[i] = embeddings_index[idx2vocab[i]]\n",
    "    else:\n",
    "        cnt += 1\n",
    "print (cnt, 'vocab has no embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "def attention_3d_block(inputs):\n",
    "    global cnt\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    TIME_STEPS = int(inputs.shape[1]) if inputs.shape[1] == in_length else out_length\n",
    "    print (TIME_STEPS, input_dim)\n",
    "    \n",
    "    a = Permute((2, 1))(inputs)\n",
    "    #a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    #if SINGLE_ATTENTION_VECTOR:\n",
    "    #a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "    #a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec_'+str(cnt))(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul_'+str(cnt), mode='mul')\n",
    "    cnt += 1\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 4096\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(in_length, input_dim), name='encoder_input')\n",
    "encoder_inputs_attn = attention_3d_block(encoder_inputs)\n",
    "encoder_inputs_drop = Dropout(drop_rate)(encoder_inputs_attn)#####\n",
    "encoder = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_drop)\n",
    "\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, vocab_size+1), name='decoder_input')\n",
    "#decoder_inputs_attn = attention_3d_block(decoder_inputs)\n",
    "#e = Embedding(len(embedding_matrix), emb_size, weights=[embedding_matrix], input_length=out_length, trainable=False)(decoder_inputs)\n",
    "decoder_inputs_drop = Dropout(drop_rate)(decoder_inputs)#####\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_drop, initial_state=encoder_states)\n",
    "#decoder_outputs_attn = attention_3d_block(decoder_outputs)\n",
    "#decoder_outputs_drop = Dropout(drop_rate)(decoder_outputs)\n",
    "decoder_dense = Dense(vocab_size+1, activation='softmax', name='softmax_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "encoder_input (InputLayer)       (None, 80, 4096)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "permute_1 (Permute)              (None, 4096, 80)      0           encoder_input[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096, 80)      6480        permute_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec_0 (Permute)        (None, 80, 4096)      0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul_0 (Merge)          (None, 80, 4096)      0           encoder_input[0][0]              \n",
      "                                                                   attention_vec_0[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)       (None, None, 6063)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 80, 4096)      0           attention_mul_0[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, None, 6063)    0           decoder_input[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)              [(None, 256), (None,  4457472     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)              [(None, None, 256), ( 6471680     dropout_2[0][0]                  \n",
      "                                                                   encoder_lstm[0][1]               \n",
      "                                                                   encoder_lstm[0][2]               \n",
      "____________________________________________________________________________________________________\n",
      "softmax_dense (Dense)            (None, None, 6063)    1558191     decoder_lstm[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 12,493,823\n",
      "Trainable params: 12,493,823\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='keras_model.png', show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: inference mode (sampling).\n",
    "\n",
    "1) encode input and retrieve initial decoder state\n",
    "\n",
    "2) run one step of decoder with this initial state\n",
    "and a \"start of sequence\" token as target.\n",
    "Output will be the next target token\n",
    "\n",
    "3) Repeat with the current target token and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "encoder_input (InputLayer)       (None, 80, 4096)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "permute_1 (Permute)              (None, 4096, 80)      0           encoder_input[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096, 80)      6480        permute_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec_0 (Permute)        (None, 80, 4096)      0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul_0 (Merge)          (None, 80, 4096)      0           encoder_input[0][0]              \n",
      "                                                                   attention_vec_0[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 80, 4096)      0           attention_mul_0[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)              [(None, 256), (None,  4457472     dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4,463,952\n",
      "Trainable params: 4,463,952\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "plot_model(encoder_model, to_file='encoder_model.png', show_shapes=True)\n",
    "print ( encoder_model.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "decoder_input (InputLayer)       (None, None, 6063)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)              [(None, None, 256), ( 6471680     decoder_input[0][0]              \n",
      "                                                                   input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "softmax_dense (Dense)            (None, None, 6063)    1558191     decoder_lstm[1][0]               \n",
      "====================================================================================================\n",
      "Total params: 8,029,871\n",
      "Trainable params: 8,029,871\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "plot_model(decoder_model, to_file='decoder_model.png', show_shapes=True)\n",
    "print ( decoder_model.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, vocab_size] = 1.\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = idx2vocab[sampled_index]\n",
    "        decoded_sentence.append(sampled_word)\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        # or sampled_word == '<pad>'\n",
    "        if (len(decoded_sentence) >= out_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "        target_seq[0, 0, sampled_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_reduce(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "    target_seq[0, 0, vocab_size] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    last_word = \"\"\n",
    "    last_last_word = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = idx2vocab[sampled_index]\n",
    "        \n",
    "        if sampled_word == last_word or sampled_word == last_last_word:\n",
    "            output_tokens[0, -1, sampled_index] = 0\n",
    "            sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = idx2vocab[sampled_index]\n",
    "        if sampled_word == last_word or sampled_word == last_last_word:\n",
    "            output_tokens[0, -1, sampled_index] = 0\n",
    "            sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = idx2vocab[sampled_index]\n",
    "        \n",
    "        last_last_word = last_word\n",
    "        last_word = sampled_word\n",
    "        \n",
    "            \n",
    "        decoded_sentence.append(sampled_word)\n",
    "\n",
    "        if (len(decoded_sentence) >= out_length):# or sampled_word == \"<pad>\":\n",
    "            stop_condition = True\n",
    "        \n",
    "\n",
    "        target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "        target_seq[0, 0, sampled_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_node(state, prob, last, word, idx):\n",
    "    seq = np.zeros((1, 1, vocab_size+1))\n",
    "    seq[0, 0, idx] = 1.\n",
    "    l = 0 if last == None else last['len']+1\n",
    "    prob = 0 if last == None else prob+last['prob']\n",
    "    node = {'state':state, 'seq':seq, 'prob':prob, 'last':last, 'len':l, 'word':word, 'idx':idx, 'next':[]}\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_beam(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    init_node = make_node(states_value, 0, None, \"<S>\", vocab_size)\n",
    "    queue = [init_node]\n",
    "    leaf_nodes = []\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    while len(queue) != 0:\n",
    "        #print (len(queue), end='\\r')\n",
    "        node = queue[0]\n",
    "        if node['len'] >= out_length or node['word'] == '<pad>':\n",
    "            leaf_nodes.append(node)\n",
    "            queue = [] if len(queue) == 1 else queue[1:]\n",
    "            break\n",
    "        target_seq = node['seq']\n",
    "        states_value = node['state']\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        for j in range(2):\n",
    "            sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = idx2vocab[sampled_index]\n",
    "            if sampled_word != node['word']:\n",
    "                new_node = make_node([h, c], output_tokens[0, -1, sampled_index], node, sampled_word, sampled_index)\n",
    "                node['next'].append(new_node)\n",
    "                queue.append(new_node)\n",
    "            output_tokens[0, -1, sampled_index] = 0\n",
    "        queue = queue[1:]\n",
    "    \n",
    "    # start search\n",
    "    max_prob = 0\n",
    "    for node in leaf_nodes:\n",
    "        tmp = node['prob']/node['len']\n",
    "        if tmp > max_prob:\n",
    "            max_prob = tmp\n",
    "            target_node = node\n",
    "    \n",
    "    while target_node['last'] != None:\n",
    "        decoded_sentence.append(target_node['word'])\n",
    "        target_node = target_node['last']\n",
    "    \n",
    "\n",
    "    return decoded_sentence[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2_1_data.bleu_eval import BLEU"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def gen_output(data, label):\n",
    "    with open(\"output_keras.txt\", 'w', encoding='utf-8') as f:\n",
    "        for i in label:\n",
    "            input_seq = np.array([data[i['id']]])\n",
    "            decoded_sentence = decode_sequence(input_seq)\n",
    "            out = []\n",
    "            for j in decoded_sentence:\n",
    "                if j == '<pad>' or j == \"<S>\":\n",
    "                    continue\n",
    "                out.append(j)\n",
    "            if len(out) == 0:\n",
    "                out.append('a')\n",
    "                \n",
    "            out = i['id'] + ',' + \" \".join(out) + '\\n'\n",
    "            f.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen output reduce\n",
    "def gen_output(data, label, decode):\n",
    "    with open(\"output_keras.txt\", 'w', encoding='utf-8') as f:\n",
    "        for i in label:\n",
    "            input_seq = np.array([data[i['id']]])\n",
    "            decoded_sentence = decode_sequence_reduce(input_seq)\n",
    "            #print (decoded_sentence)\n",
    "            out = []\n",
    "            last = \"\"\n",
    "            for j in decoded_sentence:\n",
    "                if j == \"<S>\" or j == last:\n",
    "                    continue\n",
    "                elif j == '<pad>':\n",
    "                    break\n",
    "                last = j\n",
    "                out.append(j)\n",
    "            \n",
    "                \n",
    "            out = i['id'] + ',' + \" \".join(out) + '\\n'\n",
    "            f.write(out)\n",
    "\n",
    "#gen_output_reduce(test_data, test_label)\n",
    "#cal_bleu(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bleu(label):\n",
    "    output = \"output_keras.txt\"\n",
    "    result = {}\n",
    "    with open(output, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            comma = line.index(',')\n",
    "            test_id = line[:comma]\n",
    "            caption = line[comma+1:]\n",
    "            result[test_id] = caption\n",
    "    #count by the method described in the paper https://aclanthology.info/pdf/P/P02/P02-1040.pdf\n",
    "    bleu=[]\n",
    "    for item in label:\n",
    "        score_per_video = []\n",
    "        captions = [x.rstrip('.') for x in item['caption']]\n",
    "        \n",
    "        score_per_video.append(BLEU(result[item['id']],captions,True))\n",
    "        bleu.append(score_per_video[0])\n",
    "    average = sum(bleu) / len(bleu)\n",
    "    #print(\"Average bleu score is \" + str(average))\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_outputs_and_score(label, n):\n",
    "    output = \"output_keras.txt\"\n",
    "    result = {}\n",
    "    with open(output, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            comma = line.index(',')\n",
    "            test_id = line[:comma]\n",
    "            caption = line[comma+1:]\n",
    "            result[test_id] = caption\n",
    "    #count by the method described in the paper https://aclanthology.info/pdf/P/P02/P02-1040.pdf\n",
    "    bleu=[]\n",
    "    for item in label[:n]:\n",
    "        captions = [x.rstrip('.') for x in item['caption']]\n",
    "        b = BLEU(result[item['id']],captions,True)\n",
    "        bleu.append(b)\n",
    "        print (round(b, 2), result[item['id']])\n",
    "\n",
    "    average = sum(bleu) / len(bleu)\n",
    "    #print(\"Average bleu score is \" + str(average))\n",
    "    print ('avg', average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2data(idx, x, y, data, label):\n",
    "    # x[idx] is id, y[idx][0] is label index, y[idx][1] is seq index\n",
    "    encoder_input = data[x[idx]]\n",
    "    decoder_input = label[y[idx][0]]['seq'][y[idx][1]]\n",
    "    decoder_target = np.concatenate((decoder_input[1:], np.array([0], dtype='int32')))\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, targets):\n",
    "    global train_data, train_label, batch_size, voacb_size\n",
    "    idx = np.arange(len(data))\n",
    "    while True:\n",
    "        np.random.shuffle(idx)\n",
    "        batches = [idx[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size+1)] \n",
    "        \n",
    "        for i in batches:\n",
    "            encoder_inputs, decoder_inputs, decoder_targets = [], [], []\n",
    "            for j in i:\n",
    "                x, y, z = idx2data(j, data, targets, train_data, train_label)\n",
    "                encoder_inputs.append(x)\n",
    "                decoder_inputs.append(y)\n",
    "                decoder_targets.append(z)\n",
    "            \n",
    "            encoder_inputs = np.array(encoder_inputs)\n",
    "            decoder_inputs = to_categorical(decoder_inputs, num_classes=vocab_size+1).reshape(-1, out_length, vocab_size+1)\n",
    "            decoder_targets = to_categorical(decoder_targets, num_classes=vocab_size+1).reshape(-1, out_length, vocab_size+1)\n",
    "            yield ([encoder_inputs, decoder_inputs], decoder_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_generator(data, targets):\n",
    "    global test_data, test_label, batch_size, voacb_size\n",
    "    idx = np.arange(len(data))\n",
    "    while True:\n",
    "        np.random.shuffle(idx)\n",
    "        batches = [idx[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size+1)] \n",
    "        \n",
    "        for i in batches:\n",
    "            encoder_inputs, decoder_inputs, decoder_targets = [], [], []\n",
    "            for j in i:\n",
    "                x, y, z = idx2data(j, data, targets, test_data, test_label)\n",
    "                encoder_inputs.append(x)\n",
    "                decoder_inputs.append(y)\n",
    "                decoder_targets.append(z)\n",
    "            \n",
    "            encoder_inputs = np.array(encoder_inputs)\n",
    "            decoder_inputs = to_categorical(decoder_inputs, num_classes=vocab_size+1).reshape(-1, out_length, vocab_size+1)\n",
    "            decoder_targets = to_categorical(decoder_targets, num_classes=vocab_size+1).reshape(-1, out_length, vocab_size+1)\n",
    "            yield ([encoder_inputs, decoder_inputs], decoder_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.best_score = 0\n",
    "        self.bleu_history = {'train':[], 'test':[]}\n",
    "        self.saved_model = \"\"\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        gen_output(train_data, train_label, decode_sequence_reduce)\n",
    "        show_outputs_and_score(train_label, 10)\n",
    "        try:\n",
    "            score = cal_bleu(train_label)\n",
    "            score = round(score, 3)\n",
    "            self.bleu_history['train'].append(score)\n",
    "        except ZeroDivisionError:\n",
    "            return\n",
    "        print('\\nTrain Bleu score: {}'.format(score))\n",
    "        print ()\n",
    "        \n",
    "        gen_output(test_data, test_label, decode_sequence_reduce)\n",
    "        show_outputs_and_score(test_label, 10)\n",
    "        try:\n",
    "            score = cal_bleu(test_label)\n",
    "            score = round(score, 3)\n",
    "            self.bleu_history['test'].append(score)\n",
    "        except ZeroDivisionError:\n",
    "            return\n",
    "        print('Test Bleu score: {}\\n'.format(score))\n",
    "        \n",
    "        if score > self.best_score:\n",
    "            model.save_weights('model_keras_{}.hdf5'.format(score))\n",
    "            self.saved_model = 'model_keras_{}.hdf5'.format(score)\n",
    "            if self.best_score != 0:\n",
    "                try:\n",
    "                    os.remove('model_keras_{}.hdf5'.format(self.best_score))\n",
    "                except Exception as e:\n",
    "                    print (str(e))\n",
    "                    print ('model_keras_{}.hdf5'.format(self.best_score), 'not found')\n",
    "            self.best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = ModelCheckpoint(\"model.hdf5\", monitor='val_acc', save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5)\n",
    "mycallback = MyCallback()\n",
    "callbacks_list = [mycallback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference mode training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "encoder_input (InputLayer)       (None, 80, 4096)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "permute_1 (Permute)              (None, 4096, 80)      0           encoder_input[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096, 80)      6480        permute_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec_0 (Permute)        (None, 80, 4096)      0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul_0 (Merge)          (None, 80, 4096)      0           encoder_input[0][0]              \n",
      "                                                                   attention_vec_0[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 80, 4096)      0           attention_mul_0[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "decoer_inputs_inf (InputLayer)   (None, 1, 6063)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)              [(None, 256), (None,  4457472     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)              multiple              6471680     decoer_inputs_inf[0][0]          \n",
      "                                                                   encoder_lstm[4][1]               \n",
      "                                                                   encoder_lstm[4][2]               \n",
      "                                                                   lambda_24[0][0]                  \n",
      "                                                                   decoder_lstm[62][1]              \n",
      "                                                                   decoder_lstm[62][2]              \n",
      "                                                                   lambda_25[0][0]                  \n",
      "                                                                   decoder_lstm[63][1]              \n",
      "                                                                   decoder_lstm[63][2]              \n",
      "                                                                   lambda_26[0][0]                  \n",
      "                                                                   decoder_lstm[64][1]              \n",
      "                                                                   decoder_lstm[64][2]              \n",
      "                                                                   lambda_27[0][0]                  \n",
      "                                                                   decoder_lstm[65][1]              \n",
      "                                                                   decoder_lstm[65][2]              \n",
      "                                                                   lambda_28[0][0]                  \n",
      "                                                                   decoder_lstm[66][1]              \n",
      "                                                                   decoder_lstm[66][2]              \n",
      "                                                                   lambda_29[0][0]                  \n",
      "                                                                   decoder_lstm[67][1]              \n",
      "                                                                   decoder_lstm[67][2]              \n",
      "                                                                   lambda_30[0][0]                  \n",
      "                                                                   decoder_lstm[68][1]              \n",
      "                                                                   decoder_lstm[68][2]              \n",
      "                                                                   lambda_31[0][0]                  \n",
      "                                                                   decoder_lstm[69][1]              \n",
      "                                                                   decoder_lstm[69][2]              \n",
      "                                                                   lambda_32[0][0]                  \n",
      "                                                                   decoder_lstm[70][1]              \n",
      "                                                                   decoder_lstm[70][2]              \n",
      "                                                                   lambda_33[0][0]                  \n",
      "                                                                   decoder_lstm[71][1]              \n",
      "                                                                   decoder_lstm[71][2]              \n",
      "                                                                   lambda_34[0][0]                  \n",
      "                                                                   decoder_lstm[72][1]              \n",
      "                                                                   decoder_lstm[72][2]              \n",
      "                                                                   lambda_35[0][0]                  \n",
      "                                                                   decoder_lstm[73][1]              \n",
      "                                                                   decoder_lstm[73][2]              \n",
      "                                                                   lambda_36[0][0]                  \n",
      "                                                                   decoder_lstm[74][1]              \n",
      "                                                                   decoder_lstm[74][2]              \n",
      "                                                                   lambda_37[0][0]                  \n",
      "                                                                   decoder_lstm[75][1]              \n",
      "                                                                   decoder_lstm[75][2]              \n",
      "                                                                   lambda_38[0][0]                  \n",
      "                                                                   decoder_lstm[76][1]              \n",
      "                                                                   decoder_lstm[76][2]              \n",
      "                                                                   lambda_39[0][0]                  \n",
      "                                                                   decoder_lstm[77][1]              \n",
      "                                                                   decoder_lstm[77][2]              \n",
      "                                                                   lambda_40[0][0]                  \n",
      "                                                                   decoder_lstm[78][1]              \n",
      "                                                                   decoder_lstm[78][2]              \n",
      "                                                                   lambda_41[0][0]                  \n",
      "                                                                   decoder_lstm[79][1]              \n",
      "                                                                   decoder_lstm[79][2]              \n",
      "                                                                   lambda_42[0][0]                  \n",
      "                                                                   decoder_lstm[80][1]              \n",
      "                                                                   decoder_lstm[80][2]              \n",
      "____________________________________________________________________________________________________\n",
      "softmax_dense (Dense)            multiple              1558191     decoder_lstm[62][0]              \n",
      "                                                                   decoder_lstm[63][0]              \n",
      "                                                                   decoder_lstm[64][0]              \n",
      "                                                                   decoder_lstm[65][0]              \n",
      "                                                                   decoder_lstm[66][0]              \n",
      "                                                                   decoder_lstm[67][0]              \n",
      "                                                                   decoder_lstm[68][0]              \n",
      "                                                                   decoder_lstm[69][0]              \n",
      "                                                                   decoder_lstm[70][0]              \n",
      "                                                                   decoder_lstm[71][0]              \n",
      "                                                                   decoder_lstm[72][0]              \n",
      "                                                                   decoder_lstm[73][0]              \n",
      "                                                                   decoder_lstm[74][0]              \n",
      "                                                                   decoder_lstm[75][0]              \n",
      "                                                                   decoder_lstm[76][0]              \n",
      "                                                                   decoder_lstm[77][0]              \n",
      "                                                                   decoder_lstm[78][0]              \n",
      "                                                                   decoder_lstm[79][0]              \n",
      "                                                                   decoder_lstm[80][0]              \n",
      "                                                                   decoder_lstm[81][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)               (None, 1, 6063)       0           softmax_dense[62][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)               (None, 1, 6063)       0           softmax_dense[63][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)               (None, 1, 6063)       0           softmax_dense[64][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)               (None, 1, 6063)       0           softmax_dense[65][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)               (None, 1, 6063)       0           softmax_dense[66][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)               (None, 1, 6063)       0           softmax_dense[67][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)               (None, 1, 6063)       0           softmax_dense[68][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)               (None, 1, 6063)       0           softmax_dense[69][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)               (None, 1, 6063)       0           softmax_dense[70][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)               (None, 1, 6063)       0           softmax_dense[71][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)               (None, 1, 6063)       0           softmax_dense[72][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)               (None, 1, 6063)       0           softmax_dense[73][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)               (None, 1, 6063)       0           softmax_dense[74][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)               (None, 1, 6063)       0           softmax_dense[75][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)               (None, 1, 6063)       0           softmax_dense[76][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)               (None, 1, 6063)       0           softmax_dense[77][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)               (None, 1, 6063)       0           softmax_dense[78][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)               (None, 1, 6063)       0           softmax_dense[79][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)               (None, 1, 6063)       0           softmax_dense[80][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)               (None, 20, 6063)      0           softmax_dense[62][0]             \n",
      "                                                                   softmax_dense[63][0]             \n",
      "                                                                   softmax_dense[64][0]             \n",
      "                                                                   softmax_dense[65][0]             \n",
      "                                                                   softmax_dense[66][0]             \n",
      "                                                                   softmax_dense[67][0]             \n",
      "                                                                   softmax_dense[68][0]             \n",
      "                                                                   softmax_dense[69][0]             \n",
      "                                                                   softmax_dense[70][0]             \n",
      "                                                                   softmax_dense[71][0]             \n",
      "                                                                   softmax_dense[72][0]             \n",
      "                                                                   softmax_dense[73][0]             \n",
      "                                                                   softmax_dense[74][0]             \n",
      "                                                                   softmax_dense[75][0]             \n",
      "                                                                   softmax_dense[76][0]             \n",
      "                                                                   softmax_dense[77][0]             \n",
      "                                                                   softmax_dense[78][0]             \n",
      "                                                                   softmax_dense[79][0]             \n",
      "                                                                   softmax_dense[80][0]             \n",
      "                                                                   softmax_dense[81][0]             \n",
      "====================================================================================================\n",
      "Total params: 12,493,823\n",
      "Trainable params: 12,493,823\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_drop)\n",
    "states = [state_h, state_c]\n",
    "decoder_inputs = Input(shape=(1, vocab_size+1), name='decoer_inputs_inf')\n",
    "\n",
    "\n",
    "# reinjecting the decoder's predictions into the decoder's input, just like we were doing for inference.\n",
    "all_outputs = []\n",
    "inputs = decoder_inputs\n",
    "\n",
    "for _ in range(out_length):\n",
    "    # Run the decoder on one timestep\n",
    "    outputs, state_h, state_c = decoder_lstm(inputs, initial_state=states)\n",
    "    outputs = decoder_dense(outputs) ## softmax\n",
    "    argmax_outputs = Lambda(lambda x: K.one_hot(K.argmax(x, axis=2), vocab_size+1))(outputs)\n",
    "    # Store the current prediction (we will concatenate all predictions later)\n",
    "    all_outputs.append(outputs)\n",
    "    # Reinject the outputs as inputs for the next loop iteration\n",
    "    # as well as update the states\n",
    "    inputs = argmax_outputs\n",
    "    states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "\n",
    "opt = optimizers.RMSprop(lr=0.0001)\n",
    "model_inf = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model_inf.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_inf.summary()\n",
    "plot_model(model, to_file='keras_model_inf.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print (model_inf.layers[3].name == model.layers[3].name)\n",
    "for i, j in zip(model.layers[3].get_weights(), model_inf.layers[3].get_weights()):\n",
    "    print ((i == j).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare decoder input data that just contains the start character\n",
    "\n",
    "decoder_input_data = np.zeros((num_samples, 1, num_decoder_tokens))\n",
    "\n",
    "decoder_input_data[:, 0, target_token_index['\\t']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2inf_data(idx, x, y, data, label):\n",
    "    # x[idx] is id, y[idx][0] is label index, y[idx][1] is seq index\n",
    "    encoder_input = data[x[idx]]\n",
    "    decoder_input = label[y[idx][0]]['seq'][y[idx][1]]\n",
    "    decoder_target = np.concatenate((decoder_input[1:], np.array([0], dtype='int32')))\n",
    "    return encoder_input, decoder_input[0], decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_data_generator(data, targets):\n",
    "    global train_data, train_label, batch_size, voacb_size\n",
    "    idx = np.arange(len(data))\n",
    "    while True:\n",
    "        np.random.shuffle(idx)\n",
    "        batches = [idx[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size+1)] \n",
    "        \n",
    "        for i in batches:\n",
    "            encoder_inputs, decoder_inputs, decoder_targets = [], [], []\n",
    "            for j in i:\n",
    "                x, y, z = idx2inf_data(j, data, targets, train_data, train_label)\n",
    "                encoder_inputs.append(x)\n",
    "                decoder_inputs.append(y)\n",
    "                decoder_targets.append(z)\n",
    "            \n",
    "            encoder_inputs = np.array(encoder_inputs)\n",
    "            decoder_inputs = to_categorical(decoder_inputs, num_classes=vocab_size+1).reshape(-1, 1, vocab_size+1)\n",
    "            decoder_targets = to_categorical(decoder_targets, num_classes=vocab_size+1).reshape(-1, out_length, vocab_size+1)\n",
    "            #decoder_targets = np.expand_dims(decoder_targets, axis=1)\n",
    "            #print (encoder_inputs.shape, decoder_inputs.shape, decoder_targets.shape)\n",
    "            yield ([encoder_inputs, decoder_inputs], decoder_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_validation_generator(data, targets):\n",
    "    global test_data, test_label, batch_size, voacb_size\n",
    "    idx = np.arange(len(data))\n",
    "    while True:\n",
    "        np.random.shuffle(idx)\n",
    "        batches = [idx[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size+1)] \n",
    "        \n",
    "        for i in batches:\n",
    "            encoder_inputs, decoder_inputs, decoder_targets = [], [], []\n",
    "            for j in i:\n",
    "                x, y, z = idx2inf_data(j, data, targets, test_data, test_label)\n",
    "                encoder_inputs.append(x)\n",
    "                decoder_inputs.append(y)\n",
    "                decoder_targets.append(z)\n",
    "            \n",
    "            encoder_inputs = np.array(encoder_inputs)\n",
    "            decoder_inputs = to_categorical(decoder_inputs, num_classes=vocab_size+1).reshape(-1, 1, vocab_size+1)\n",
    "            decoder_targets = to_categorical(decoder_targets, num_classes=vocab_size+1).reshape(-1, out_length, vocab_size+1)\n",
    "            #decoder_targets = np.expand_dims(decoder_targets, axis=1)\n",
    "            yield ([encoder_inputs, decoder_inputs], decoder_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['loss', 'val_loss', 'acc', 'val_acc']\n",
    "myhistory = {i:[] for i in metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.5970 - acc: 0.73281.0 a woman is walking a horse\n",
      "0.86 a man is pouring into a bowl\n",
      "1.0 a loris is eating a food\n",
      "1.0 a person is seasoning eggs\n",
      "0.8 a person is cutting a\n",
      "0.83 a are is running a the\n",
      "1.0 a man is talking\n",
      "0.83 a woman is peeling a garlic\n",
      "1.0 a man is doing\n",
      "1.0 a man is doing ups\n",
      "avg 0.9323809523809523\n",
      "\n",
      "Train Bleu score: 0.927\n",
      "\n",
      "0.83 a man is peeling a of\n",
      "0.5 a man is shooting a water\n",
      "0.83 a man is doing a on\n",
      "0.67 a man is playing a toy\n",
      "0.8 a man is a on\n",
      "0.5 a dog is eating a from\n",
      "0.83 a baby is eating a baby\n",
      "0.29 a panda is walking on a snow\n",
      "0.67 a man is doing on a\n",
      "0.83 a man is putting a box\n",
      "avg 0.6752380952380952\n",
      "Test Bleu score: 0.684\n",
      "\n",
      "758/758 [==============================] - 220s - loss: 1.5970 - acc: 0.7328 - val_loss: 1.7403 - val_acc: 0.7173\n",
      "Epoch 2/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.3733 - acc: 0.75690.83 a woman is a woman horse\n",
      "1.0 a man is cutting butter into a bowl\n",
      "1.0 a animal is eating\n",
      "1.0 a person is seasoning eggs in a bowl\n",
      "0.83 a person is adding a cameras\n",
      "1.0 clouds are moving a\n",
      "1.0 a man is talking\n",
      "1.0 a woman is peeling an apple\n",
      "1.0 a man is doing\n",
      "1.0 a man is doing push ups\n",
      "avg 0.9666666666666668\n",
      "\n",
      "Train Bleu score: 0.956\n",
      "\n",
      "0.8 a man is a hands\n",
      "0.5 a man is jumping a dog\n",
      "0.6 a boy is playing a\n",
      "0.67 a baby is playing a ball\n",
      "0.8 a man is a banana\n",
      "0.5 a dog is sitting a tail\n",
      "0.67 a baby is laughing a baby\n",
      "0.29 a panda is walking on a ground\n",
      "0.5 a woman is up a horse\n",
      "0.67 a man is cutting a box\n",
      "avg 0.5985714285714285\n",
      "Test Bleu score: 0.679\n",
      "\n",
      "758/758 [==============================] - 220s - loss: 1.3737 - acc: 0.7569 - val_loss: 1.7235 - val_acc: 0.7225\n",
      "Epoch 3/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.2898 - acc: 0.76630.86 a woman is sitting on the horse\n",
      "1.0 a man is cutting butter into a bowl\n",
      "1.0 a animal is eating a food\n",
      "1.0 a man is adding eggs in a bowl\n",
      "1.0 a person is two cameras\n",
      "1.0 clouds are moving a building\n",
      "1.0 a man is talking\n",
      "1.0 a woman is peeling a apple\n",
      "1.0 a man is doing\n",
      "1.0 a man is doing push ups\n",
      "avg 0.9857142857142858\n",
      "\n",
      "Train Bleu score: 0.965\n",
      "\n",
      "0.67 a man is pouring a food\n",
      "0.5 a woman is shooting a gun\n",
      "0.67 a man is playing a toy\n",
      "0.67 a baby is playing a ball\n",
      "0.67 a man is playing a banana\n",
      "0.71 a dog is sitting in a of\n",
      "0.83 a baby is playing a her\n",
      "0.5 a baby is playing\n",
      "0.5 a man is walking a up\n",
      "0.75 a man is cutting a piece of a\n",
      "avg 0.6464285714285714\n",
      "Test Bleu score: 0.683\n",
      "\n",
      "758/758 [==============================] - 220s - loss: 1.2899 - acc: 0.7663 - val_loss: 1.6626 - val_acc: 0.7322\n",
      "Epoch 4/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.2414 - acc: 0.77150.86 a woman is sitting on a horse\n",
      "1.0 a man is cutting butter into a bowl\n",
      "1.0 a animal is eating a chair\n",
      "1.0 a man is seasoning eggs\n",
      "0.88 a person is cameras two with a cameras\n",
      "1.0 clouds are moving in a sky\n",
      "1.0 a man is talking\n",
      "1.0 a woman is peeling an apple\n",
      "1.0 a man is doing exercises\n",
      "1.0 a man is doing push ups\n",
      "avg 0.9732142857142858\n",
      "\n",
      "Train Bleu score: 0.971\n",
      "\n",
      "0.67 a man is pouring a food\n",
      "0.67 a man is shooting a with\n",
      "0.5 a boy is riding a wall\n",
      "0.67 a baby is playing a ball\n",
      "0.83 a man is talking a woman\n",
      "0.71 a puppy is sitting in a bed\n",
      "0.83 a baby is eating a baby\n",
      "0.29 a panda is climbing on a ground\n",
      "0.86 a girl is doing on a road\n",
      "0.88 a man is putting a piece of a\n",
      "avg 0.6898809523809523\n",
      "Test Bleu score: 0.691\n",
      "\n",
      "758/758 [==============================] - 220s - loss: 1.2413 - acc: 0.7715 - val_loss: 1.6750 - val_acc: 0.7318\n",
      "Epoch 5/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.2121 - acc: 0.77561.0 a woman is walking on a horse\n",
      "1.0 a man is cutting butter into a bowl\n",
      "1.0 a animal is eating\n",
      "1.0 a man is adding eggs to a bowl\n",
      "1.0 a person is burning two cameras\n",
      "0.83 clouds are moving in a moving\n",
      "1.0 a man is speaking\n",
      "1.0 a woman is peeling an apple\n",
      "0.8 a man is doing rope\n",
      "1.0 a man is doing push ups\n",
      "avg 0.9633333333333333\n",
      "\n",
      "Train Bleu score: 0.98\n",
      "\n",
      "0.6 a man is pouring some\n",
      "0.67 a man is shooting a of\n",
      "0.67 a man is doing a wall\n",
      "0.86 a small is playing with a toy\n",
      "0.57 a man is talking to a man\n",
      "0.57 the dog is sitting in the water\n",
      "0.83 a baby is eating a baby\n",
      "0.38 a baby panda is climbing on a ground\n",
      "0.5 a man is doing a machine\n",
      "0.78 a man is putting a piece of a paper\n",
      "avg 0.6419444444444443\n",
      "Test Bleu score: 0.678\n",
      "\n",
      "758/758 [==============================] - 219s - loss: 1.2123 - acc: 0.7756 - val_loss: 1.6674 - val_acc: 0.7318\n",
      "Epoch 6/15\n",
      "155/758 [=====>........................] - ETA: 105s - loss: 1.1677 - acc: 0.7782"
     ]
    }
   ],
   "source": [
    "# pretrain\n",
    "history = model.fit_generator(data_generator(X, Y), steps_per_epoch=int((len(Y)+batch_size-1)/batch_size), \n",
    "                                      validation_data=validation_generator(X_test, Y_test), \n",
    "                                      validation_steps=int((len(Y_test)+batch_size-1)/batch_size),\n",
    "                                      epochs=15, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 2.7090 - acc: 0.65700.45 a man is a\n",
      "0.78 a man is a\n",
      "0.75 a man is a\n",
      "1.0 a man is a\n",
      "0.75 a man is a\n",
      "0.75 a man is a\n",
      "1.0 a man is a\n",
      "0.58 a man is a\n",
      "1.0 a man is a\n",
      "0.78 a man is a\n",
      "avg 0.7846600148230838\n",
      "\n",
      "Train Bleu score: 0.714\n",
      "\n",
      "0.78 a man is a\n",
      "0.75 a man is a\n",
      "1.0 a man is a\n",
      "0.58 a man is a\n",
      "1.0 a man is a\n",
      "0.58 a man is a\n",
      "0.58 a man is a\n",
      "0.0 a man is a\n",
      "0.58 a man is a\n",
      "0.78 a man is a\n",
      "avg 0.6644003915357024\n",
      "Test Bleu score: 0.696\n",
      "\n",
      "758/758 [==============================] - 239s - loss: 2.7083 - acc: 0.6570 - val_loss: 2.2347 - val_acc: 0.6942\n",
      "Epoch 2/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 2.1220 - acc: 0.69570.65 a man is a the\n",
      "1.0 a man is a the\n",
      "0.8 a man is a the\n",
      "1.0 a man is a the\n",
      "0.8 a man is a the\n",
      "0.8 a man is a the\n",
      "1.0 a man is a the\n",
      "0.58 a man is a\n",
      "1.0 a man is a the\n",
      "1.0 a man is a the\n",
      "avg 0.8639085189765939\n",
      "\n",
      "Train Bleu score: 0.807\n",
      "\n",
      "1.0 a man is a the\n",
      "0.65 a man is a the\n",
      "1.0 a man is a\n",
      "0.8 a man is a the\n",
      "1.0 a man is a the\n",
      "0.8 a man is a the\n",
      "0.58 a man is a\n",
      "0.2 a man is a the\n",
      "0.8 a man is a the\n",
      "1.0 a man is a the\n",
      "avg 0.7839085189765939\n",
      "Test Bleu score: 0.789\n",
      "\n",
      "758/758 [==============================] - 231s - loss: 2.1218 - acc: 0.6957 - val_loss: 2.1712 - val_acc: 0.6907\n",
      "Epoch 3/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 2.0333 - acc: 0.70140.65 a man is a the\n",
      "1.0 a man is a the\n",
      "0.8 a cat is a the\n",
      "0.8 a woman is a into\n",
      "0.8 a man is a the\n",
      "0.8 a man is a the\n",
      "0.8 a man is playing a\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is a the\n",
      "1.0 a man is a the\n",
      "avg 0.8454984602462385\n",
      "\n",
      "Train Bleu score: 0.826\n",
      "\n",
      "1.0 a man is a the\n",
      "0.65 a man is a the\n",
      "1.0 a man is a the\n",
      "0.8 a man is a the\n",
      "0.8 a man is playing a\n",
      "0.8 a cat is a the\n",
      "0.8 a woman is a the\n",
      "0.0 a cat is a\n",
      "0.8 a man is a the\n",
      "1.0 a man is a the\n",
      "avg 0.7654984602462385\n",
      "Test Bleu score: 0.786\n",
      "\n",
      "758/758 [==============================] - 229s - loss: 2.0347 - acc: 0.7013 - val_loss: 2.1127 - val_acc: 0.6993\n",
      "Epoch 4/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.9699 - acc: 0.70550.65 a man is a the\n",
      "0.78 a man is a\n",
      "0.75 a cat is a\n",
      "1.0 a man is a into\n",
      "0.75 a is cutting a\n",
      "0.75 a man is a\n",
      "0.75 a man is playing\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is a\n",
      "1.0 a man is a the\n",
      "avg 0.823378538553379\n",
      "\n",
      "Train Bleu score: 0.815\n",
      "\n",
      "0.78 a man is a\n",
      "0.75 a man is a\n",
      "1.0 a man is a the\n",
      "1.0 a dog is playing a\n",
      "0.8 a man is playing a\n",
      "0.8 a cat is a the\n",
      "0.58 a woman is a\n",
      "0.25 a baby is a\n",
      "0.58 a man is a\n",
      "0.78 a man is a\n",
      "avg 0.7325802740749917\n",
      "Test Bleu score: 0.762\n",
      "\n",
      "758/758 [==============================] - 231s - loss: 1.9698 - acc: 0.7055 - val_loss: 2.0903 - val_acc: 0.7005\n",
      "Epoch 5/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.9174 - acc: 0.70880.65 a man is a the\n",
      "1.0 a man is a into\n",
      "0.8 a cat is a the\n",
      "1.0 a man is a into\n",
      "0.8 a man is a the\n",
      "1.0 a are is a\n",
      "0.8 a man is playing a\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is a the\n",
      "1.0 a man is a the\n",
      "avg 0.8854984602462384\n",
      "\n",
      "Train Bleu score: 0.851\n",
      "\n",
      "1.0 a man is a the\n",
      "0.65 a man is a on\n",
      "1.0 a man is a the\n",
      "1.0 a dog is playing a\n",
      "1.0 a man is a the\n",
      "0.8 a cat is a the\n",
      "1.0 a baby is a the\n",
      "0.4 a baby is playing a\n",
      "0.8 a man is a the\n",
      "0.8 a man is a into\n",
      "avg 0.8454984602462385\n",
      "Test Bleu score: 0.811\n",
      "\n",
      "758/758 [==============================] - 232s - loss: 1.9181 - acc: 0.7088 - val_loss: 2.0577 - val_acc: 0.7021\n",
      "Epoch 6/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.8744 - acc: 0.71210.65 a man is a the\n",
      "1.0 a man is a into\n",
      "0.8 a cat is eating a\n",
      "1.0 a man is a into\n",
      "0.8 a is playing a on\n",
      "1.0 a are is a\n",
      "0.8 a man is playing a\n",
      "0.78 a woman is a\n",
      "1.0 a man is a the\n",
      "1.0 a man is a the\n",
      "avg 0.883378538553379\n",
      "\n",
      "Train Bleu score: 0.844\n",
      "\n",
      "1.0 a man is a the\n",
      "0.65 a man is a on\n",
      "1.0 a man is a the\n",
      "1.0 a dog is playing a\n",
      "1.0 a man is a\n",
      "0.8 a cat is a the\n",
      "0.78 a baby is a\n",
      "0.5 a panda is playing\n",
      "0.8 a man is a the\n",
      "0.8 a man is a into\n",
      "avg 0.8333785385533791\n",
      "Test Bleu score: 0.802\n",
      "\n",
      "758/758 [==============================] - 232s - loss: 1.8740 - acc: 0.7121 - val_loss: 2.0523 - val_acc: 0.7015\n",
      "Epoch 7/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.8359 - acc: 0.71450.65 a man is a the\n",
      "1.0 a man is a into\n",
      "0.8 a cat is eating a\n",
      "1.0 a man is adding a\n",
      "0.8 a person is a into\n",
      "1.0 a are is a the\n",
      "0.75 a man is eating\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is a\n",
      "1.0 a man is a the\n",
      "avg 0.8804984602462385\n",
      "\n",
      "Train Bleu score: 0.86\n",
      "\n",
      "0.8 a man is a into\n",
      "0.65 a man is a on\n",
      "1.0 a man is a the\n",
      "1.0 a dog is playing a\n",
      "1.0 a man is a\n",
      "0.8 a cat is a the\n",
      "0.78 a baby is a\n",
      "0.4 a panda is playing a\n",
      "0.8 a man is a on\n",
      "0.8 a man is a into\n",
      "avg 0.8033785385533789\n",
      "Test Bleu score: 0.784\n",
      "\n",
      "758/758 [==============================] - 232s - loss: 1.8361 - acc: 0.7144 - val_loss: 2.0573 - val_acc: 0.6984\n",
      "Epoch 8/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.8017 - acc: 0.71700.65 a woman is a woman\n",
      "1.0 a man is a into\n",
      "0.8 a cat is eating a\n",
      "1.0 a man is adding a\n",
      "0.8 a is eating a on\n",
      "1.0 a are is a\n",
      "1.0 a man is talking\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is a\n",
      "1.0 a man is a the\n",
      "avg 0.9054984602462385\n",
      "\n",
      "Train Bleu score: 0.871\n",
      "\n",
      "0.78 a man is a\n",
      "0.65 a woman is a on\n",
      "1.0 a man is a the\n",
      "1.0 a dog is playing a\n",
      "1.0 a man is a\n",
      "0.6 a dog is eating a\n",
      "1.0 a baby is a on\n",
      "0.5 a panda is playing\n",
      "0.8 a man is a on\n",
      "1.0 a man is a the\n",
      "avg 0.8333785385533791\n",
      "Test Bleu score: 0.775\n",
      "\n",
      "758/758 [==============================] - 231s - loss: 1.8013 - acc: 0.7170 - val_loss: 2.0640 - val_acc: 0.7002\n",
      "Epoch 9/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.7696 - acc: 0.71930.65 a man is a woman\n",
      "1.0 a man is a into\n",
      "0.8 a person is eating a\n",
      "1.0 a man is adding a\n",
      "0.8 a is being a on\n",
      "1.0 a are of a\n",
      "1.0 a man is talking\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is a\n",
      "1.0 a man is a the\n",
      "avg 0.9054984602462385\n",
      "\n",
      "Train Bleu score: 0.88\n",
      "\n",
      "0.78 a man is a\n",
      "0.65 a man is a on\n",
      "1.0 a man is a on\n",
      "1.0 a dog is playing a\n",
      "1.0 a man is a\n",
      "0.8 a dog is a the\n",
      "1.0 a baby is a on\n",
      "0.4 a panda is playing a\n",
      "0.58 a man is a\n",
      "1.0 a man is a the\n",
      "avg 0.8217885972837344\n",
      "Test Bleu score: 0.773\n",
      "\n",
      "758/758 [==============================] - 231s - loss: 1.7688 - acc: 0.7194 - val_loss: 2.0403 - val_acc: 0.7012\n",
      "Epoch 10/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.7404 - acc: 0.72170.65 a woman is a woman\n",
      "1.0 a man is a into\n",
      "1.0 a baby is eating a\n",
      "1.0 a person is adding a\n",
      "1.0 a person is a on\n",
      "1.0 a are of a\n",
      "1.0 a man is talking\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is a\n",
      "0.8 a man is playing a\n",
      "avg 0.9254984602462386\n",
      "\n",
      "Train Bleu score: 0.873\n",
      "\n",
      "0.58 a man is eating\n",
      "0.75 a man is a\n",
      "1.0 a man is a the\n",
      "0.58 a baby is playing\n",
      "0.8 a man is playing a\n",
      "0.6 a dog is eating a\n",
      "0.78 a baby is a\n",
      "0.75 a panda are playing\n",
      "0.8 a man is on a\n",
      "1.0 a man is a the\n",
      "avg 0.7647001957678511\n",
      "Test Bleu score: 0.726\n",
      "\n",
      "758/758 [==============================] - 222s - loss: 1.7399 - acc: 0.7217 - val_loss: 2.0179 - val_acc: 0.7000\n",
      "Epoch 11/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.7146 - acc: 0.72370.65 a woman is a woman\n",
      "1.0 a man is a into\n",
      "1.0 a animal is eating a\n",
      "1.0 a person is adding a\n",
      "1.0 a person is a on\n",
      "1.0 a are of a\n",
      "1.0 a man is talking\n",
      "0.8 a woman is slicing a\n",
      "1.0 a man is doing\n",
      "1.0 a man is doing a\n",
      "avg 0.9454984602462385\n",
      "\n",
      "Train Bleu score: 0.906\n",
      "\n",
      "1.0 a man is a the\n",
      "0.75 a woman is a\n",
      "1.0 a man is a on\n",
      "1.0 a dog is playing a\n",
      "1.0 a man is a\n",
      "0.6 a dog is eating a\n",
      "1.0 a baby is a on\n",
      "0.5 a panda are is\n",
      "0.8 a man is on a\n",
      "1.0 a man is a the\n",
      "avg 0.8649999999999999\n",
      "Test Bleu score: 0.783\n",
      "\n",
      "758/758 [==============================] - 248s - loss: 1.7140 - acc: 0.7238 - val_loss: 2.0305 - val_acc: 0.6997\n",
      "Epoch 12/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.6908 - acc: 0.72560.82 a woman is a the\n",
      "1.0 a man is a into\n",
      "1.0 a animal is eating a\n",
      "1.0 a person is adding a\n",
      "1.0 someone person is a on\n",
      "1.0 a are of a\n",
      "1.0 a man is talking\n",
      "0.78 a woman is peeling\n",
      "1.0 a man is doing\n",
      "1.0 a man is doing a\n",
      "avg 0.9597531536149386\n",
      "\n",
      "Train Bleu score: 0.888\n",
      "\n",
      "0.78 a man is a\n",
      "0.75 a are is a\n",
      "1.0 a man is a\n",
      "0.58 a baby are playing\n",
      "1.0 a man is eating\n",
      "0.6 a dog is eating a\n",
      "1.0 a baby is eating a\n",
      "1.0 two panda are playing\n",
      "0.6 a man is doing a\n",
      "0.86 a man is a pizza of a\n",
      "avg 0.8170044227517815\n",
      "Test Bleu score: 0.731\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/758 [==============================] - 232s - loss: 1.6904 - acc: 0.7257 - val_loss: 2.0084 - val_acc: 0.6987\n",
      "Epoch 13/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.6684 - acc: 0.72740.83 a woman is a woman and\n",
      "1.0 a man is a into\n",
      "1.0 a animal is eating a\n",
      "1.0 a man is adding a\n",
      "1.0 a person is a on\n",
      "0.75 two are of a\n",
      "1.0 a man is talking\n",
      "1.0 a woman is peeling a\n",
      "1.0 a man is doing a\n",
      "1.0 a man is doing a\n",
      "avg 0.9583333333333334\n",
      "\n",
      "Train Bleu score: 0.93\n",
      "\n",
      "1.0 a man is a the\n",
      "0.65 a woman is a the\n",
      "0.83 a man is doing a on\n",
      "0.8 a baby is playing a\n",
      "1.0 a man is a the\n",
      "0.8 a dog is a the\n",
      "1.0 a baby is a on\n",
      "0.4 a panda is playing a\n",
      "0.67 a man is doing a on\n",
      "1.0 a man is a the of a\n",
      "avg 0.8154984602462386\n",
      "Test Bleu score: 0.774\n",
      "\n",
      "758/758 [==============================] - 232s - loss: 1.6689 - acc: 0.7273 - val_loss: 2.0301 - val_acc: 0.6995\n",
      "Epoch 14/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.6477 - acc: 0.72901.0 a woman is a the on\n",
      "1.0 a man is a into\n",
      "1.0 a animal is eating a\n",
      "1.0 a person is adding a\n",
      "1.0 a person is a on\n",
      "0.75 two are of a\n",
      "1.0 a man is talking\n",
      "1.0 a woman is peeling a\n",
      "1.0 a man is doing\n",
      "1.0 a man is doing a\n",
      "avg 0.975\n",
      "\n",
      "Train Bleu score: 0.936\n",
      "\n",
      "1.0 a man is a the\n",
      "0.65 a woman is a the\n",
      "1.0 a man is a on\n",
      "0.8 a baby is playing a\n",
      "1.0 a man is a\n",
      "0.8 a dog is a the\n",
      "1.0 a baby is a her\n",
      "0.5 a panda is are\n",
      "0.6 a man is doing on\n",
      "1.0 a man is a the of a\n",
      "avg 0.8354984602462384\n",
      "Test Bleu score: 0.767\n",
      "\n",
      "758/758 [==============================] - 232s - loss: 1.6472 - acc: 0.7291 - val_loss: 2.0511 - val_acc: 0.6946\n",
      "Epoch 15/15\n",
      "757/758 [============================>.] - ETA: 0s - loss: 1.6275 - acc: 0.73031.0 a woman is a the horse a\n",
      "0.83 a man is pouring a into\n",
      "1.0 a animal is eating a\n",
      "1.0 a person is adding eggs\n",
      "1.0 someone person is a on\n",
      "0.8 two are of a the\n",
      "1.0 a man is talking\n",
      "1.0 a woman is peeling a\n",
      "1.0 a man is doing a\n",
      "1.0 a man is doing a ups\n",
      "avg 0.9633333333333333\n",
      "\n",
      "Train Bleu score: 0.951\n",
      "\n",
      "1.0 a man is a the\n",
      "0.65 a woman is a the\n",
      "0.83 a man is doing a on\n",
      "1.0 a dog is playing a\n",
      "0.8 a man is playing a\n",
      "0.83 a dog is a the in\n",
      "1.0 a baby is a on\n",
      "0.5 a panda is playing\n",
      "0.67 a man is doing a on\n",
      "0.86 a man is a pizza of a\n",
      "avg 0.8145460792938577\n",
      "Test Bleu score: 0.779\n",
      "\n",
      "758/758 [==============================] - 232s - loss: 1.6276 - acc: 0.7304 - val_loss: 2.0271 - val_acc: 0.6983\n"
     ]
    }
   ],
   "source": [
    "history = model_inf.fit_generator(inf_data_generator(X, Y), \n",
    "                                  steps_per_epoch=int((len(Y)+batch_size-1)/batch_size), \n",
    "                                  validation_data=inf_validation_generator(X_test, Y_test), \n",
    "                                  validation_steps=int((len(Y_test)+batch_size-1)/batch_size),\n",
    "                                  epochs=15, \n",
    "                                  callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in metrics:\n",
    "    myhistory[i].append(history.history[i][-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('hw2/vocab2idx', 'wb') as f:\n",
    "    pickle.dump(vocab2idx, f)\n",
    "with open('hw2/idx2vocab', 'wb') as f:\n",
    "    pickle.dump(idx2vocab, f)\n",
    "with open('hw2/correct_words', 'wb') as f:\n",
    "    pickle.dump(correct_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6939950765347153"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_output(test_data, test_label, decode_sequence_reduce)\n",
    "cal_bleu(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_force_ratio = 100\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    print ('epoch', epoch)\n",
    "    try:\n",
    "        #if np.random.random() < teacher_force_ratio:\n",
    "        print ('teacher forcing')\n",
    "        history = model.fit_generator(data_generator(X, Y), steps_per_epoch=int((len(Y)+batch_size-1)/batch_size), \n",
    "                                      validation_data=validation_generator(X_test, Y_test), \n",
    "                                      validation_steps=int((len(Y_test)+batch_size-1)/batch_size),\n",
    "                                      epochs=1, callbacks=callbacks_list)\n",
    "        #else:\n",
    "        print ('inference mode')\n",
    "        history = model_inf.fit_generator(inf_data_generator(X, Y), \n",
    "                                          steps_per_epoch=int((len(Y)+batch_size-1)/batch_size), \n",
    "                                          validation_data=inf_validation_generator(X_test, Y_test), \n",
    "                                          validation_steps=int((len(Y_test)+batch_size-1)/batch_size),\n",
    "                                          epochs=1, \n",
    "                                          callbacks=callbacks_list)\n",
    "    except KeyboardInterrupt:\n",
    "        print ('KeyboardInterrupt')\n",
    "        break\n",
    "        \n",
    "    for i in metrics:\n",
    "        myhistory[i].append(history.history[i][-1])\n",
    "        \n",
    "    #if (epoch+1)%4 == 0:\n",
    "    #    teacher_force_ratio -= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mycallback.bleu_history['train'])\n",
    "plt.plot(mycallback.bleu_history['test'])\n",
    "plt.title('bleu score')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(history.history['loss'], label='loss', c='b')\n",
    "ax1.plot(history.history['val_loss'], label='val_loss', c='b', linestyle='--')\n",
    "ax1.set_ylabel('loss')\n",
    "#ax1.legend(['loss', 'val_loss'])\n",
    "\n",
    "\n",
    "ax2.plot(mycallback.bleu_history['train'], label='bleu', c='r')\n",
    "ax2.plot(mycallback.bleu_history['test'], label='val_bleu', c='r', linestyle='--')\n",
    "ax2.set_ylabel('bleu score')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(history.history['acc'], label='acc', c='b')\n",
    "ax1.plot(history.history['val_acc'], label='val_acc', c='b', linestyle='--')\n",
    "ax1.set_ylabel('accuracy')\n",
    "\n",
    "ax2.plot(mycallback.bleu_history['train'], label='bleu', c='r')\n",
    "ax2.plot(mycallback.bleu_history['test'], label='val_bleu', c='r', linestyle='--')\n",
    "ax2.set_ylabel('bleu score')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_0.694.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_keras_0.811.hdf5 0.811\n"
     ]
    }
   ],
   "source": [
    "print (mycallback.saved_model, mycallback.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('model_0.694.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_keras_0.694.hdf5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def decode_sequence_reduce(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "    target_seq[0, 0, vocab_size] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    last_word = \"\"\n",
    "    last_last_word = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = idx2vocab[sampled_index]\n",
    "        \n",
    "        if sampled_word == last_word or sampled_word == last_last_word:\n",
    "            output_tokens[0, -1, sampled_index] = 0\n",
    "            sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = idx2vocab[sampled_index]\n",
    "        if sampled_word == last_word or sampled_word == last_last_word:\n",
    "            output_tokens[0, -1, sampled_index] = 0\n",
    "            sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = idx2vocab[sampled_index]\n",
    "        \n",
    "        \n",
    "\n",
    "        if (len(decoded_sentence) >= out_length):\n",
    "            stop_condition = True\n",
    "        elif sampled_word == \"<pad>\":\n",
    "            stop_condition = True\n",
    "            if last_word == 'a':\n",
    "                output_tokens[0, -1, sampled_index] = 0\n",
    "                sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "                sampled_word = idx2vocab[sampled_index]\n",
    "                decoded_sentence.append(sampled_word)\n",
    "        else:\n",
    "            last_last_word = last_word\n",
    "            last_word = sampled_word   \n",
    "            decoded_sentence.append(sampled_word)\n",
    "        \n",
    "\n",
    "        target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "        target_seq[0, 0, sampled_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_output(test_data, test_label, decode_sequence_beam)\n",
    "cal_bleu(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_outputs_and_score(test_label, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_reduce_2(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "    target_seq[0, 0, vocab_size] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    last_word = \"\"\n",
    "    last_last_word = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = idx2vocab[sampled_index]\n",
    "        \n",
    "        if sampled_word == last_word or sampled_word == last_last_word:\n",
    "            output_tokens[0, -1, sampled_index] = 0\n",
    "            sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = idx2vocab[sampled_index]\n",
    "        if sampled_word == last_word or sampled_word == last_last_word:\n",
    "            output_tokens[0, -1, sampled_index] = 0\n",
    "            sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = idx2vocab[sampled_index]\n",
    "        \n",
    "        last_last_word = last_word\n",
    "        last_word = sampled_word\n",
    "            \n",
    "        \n",
    "        \n",
    "        if (len(decoded_sentence) >= out_length) or sampled_word == \"<pad>\":\n",
    "            tag = nltk.pos_tag([last_last_word])[0][1]\n",
    "            if  tag == 'DT' or tag == 'IN':\n",
    "                #decoded_sentence.append('!')\n",
    "                while True:\n",
    "                    output_tokens[0, -1, sampled_index] = 0\n",
    "                    sampled_index = np.argmax(output_tokens[0, -1, :])\n",
    "                    sampled_word = idx2vocab[sampled_index]\n",
    "                    if nltk.pos_tag([sampled_word])[0][1] == 'NN':\n",
    "                        decoded_sentence.append(sampled_word)\n",
    "                        break\n",
    "            stop_condition = True\n",
    "            continue\n",
    "            \n",
    "        decoded_sentence.append(sampled_word)\n",
    "\n",
    "        target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "        target_seq[0, 0, sampled_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_label[:20]:\n",
    "    input_seq = np.array([test_data[i['id']]])\n",
    "    decoded_sentence = decode_sequence_reduce_2(input_seq)\n",
    "    print (i['caption'][0])\n",
    "    print (decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_keras.txt\", 'w', encoding='utf-8') as f:\n",
    "    for i in test_label:\n",
    "        input_seq = np.array([test_data[i['id']]])\n",
    "        decoded_sentence = decode_sequence_reduce_2(input_seq)\n",
    "        #print (decoded_sentence)\n",
    "        out = []\n",
    "        last = \"\"\n",
    "        for j in decoded_sentence:\n",
    "            if j == '<pad>' or j == \"<S>\" or j == last:\n",
    "                continue\n",
    "            last = j\n",
    "            out.append(j)\n",
    "\n",
    "\n",
    "        out = i['id'] + ',' + \" \".join(out) + '\\n'\n",
    "        f.write(out)\n",
    "    \n",
    "cal_bleu(test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
